{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Train Your Own Model on ImageNet\n==========================================\n\n``ImageNet`` is the most well-known dataset for image classification.\nSince it was published, most of the research that advances the state-of-the-art\nof image classification was based on this dataset.\n\nAlthough there are a lot of available models, it is still a non-trivial task to\ntrain a state-of-the-art model on ``ImageNet`` from scratch.\nIn this tutorial, we will smoothly walk\nyou through the process of training a model on ``ImageNet``.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The rest of the tutorial walks you through the details of ``ImageNet`` training.\n    If you want a quick start without knowing the details, try downloading\n    this script and start training with just one command.\n\n    :download:`Download train_imagenet.py<../../../scripts/classification/imagenet/train_imagenet.py>`\n\n    The commands used to reproduce results from papers are given in our\n    `Model Zoo <../../model_zoo/index.html>`__.</p></div>\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Since real training is extremely resource consuming, we don't actually\n    execute code blocks in this tutorial.</p></div>\n\n\nPrerequisites\n-------------\n\n**Expertise**\n\nWe assume readers have a basic understanding of ``Gluon``, we suggest\nyou start with `Gluon Crash Course <http://gluon-crash-course.mxnet.io/index.html>`__ .\n\nAlso, we assume that readers have gone through previous tutorials on\n`CIFAR10 Training <dive_deep_cifar10.html>`_ and `ImageNet Demo <demo_imagenet.html>`_ .\n\n**Data Preparation**\n\nUnlike ``CIFAR10``, we need to prepare the data manually.\nIf you haven't done so, please go through our tutorial on\n`Prepare ImageNet Data <../examples_datasets/imagenet.html>`_ .\n\n**Hardware**\n\nTraining deep learning models on a dataset of over one million images is\nvery resource demanding.\nTwo main bottlenecks are tensor computation and data IO.\n\nFor tensor computation, it is recommended to use a GPU, preferably a high-end\none.\nUsing multiple GPUs together will further reduce training time.\n\nFor data IO, we recommend a fast CPU and a SSD disk. Data loading can greatly benefit\nfrom multiple CPU threads, and a fast SSD disk. Note that in total the compressed\nand extracted ``ImageNet`` data could occupy around 300GB disk space, thus a SSD with\nat least 300GB is required.\n\nNetwork structure\n-----------------\n\nFinished preparation? Let's get started!\n\nFirst, import the necessary libraries into python.\n\n.. code-block:: python\n\n    import argparse, time\n\n    import numpy as np\n    import mxnet as mx\n\n    from mxnet import gluon, nd\n    from mxnet import autograd as ag\n    from mxnet.gluon import nn\n\n    from gluoncv.model_zoo import get_model\n    from gluoncv.utils import makedirs, TrainingHistory\n\nIn this tutorial we use ``ResNet50_v2``, a network with balanced prediction\naccuracy and computational cost.\n\n.. code-block:: python\n\n    # number of GPUs to use\n    num_gpus = 4\n    ctx = [mx.gpu(i) for i in range(num_gpus)]\n\n    # Get the model ResNet50_v2, with 10 output classes\n    net = get_model('ResNet50_v2', classes=1000)\n    net.initialize(mx.init.MSRAPrelu(), ctx = ctx)\n\n\nNote that the ResNet model we use here for ``ImageNet`` is different in structure from\nthe one we used to train ``CIFAR10``. Please refer to the original paper or\nGluonCV codebase for details.\n\nData Augmentation with ImageRecordIter\n---------------------------------\n\nWhen training a small network with multiple GPUs, data IO could be a bottleneck for the performance.\nBesides data loader from gluon, we recommend to use the `ImageRecordIter` interface to load and\nprocess data from record files.\nFor more information on record files, please refer to `our tutorial <../examples_datasets/recordio.html>`_.\n\nData augmentation is essential for a good result.\nWe can set related parameters in the `ImageRecordIter`.\n\n.. code-block:: python\n\n    jitter_param = 0.4\n    lighting_param = 0.1\n    mean_rgb = [123.68, 116.779, 103.939]\n    std_rgb = [58.393, 57.12, 57.375]\n\n    train_data = mx.io.ImageRecordIter(\n        path_imgrec         = '~/.mxnet/datasets/imagenet/rec/train.rec',\n        path_imgidx         = '~/.mxnet/datasets/imagenet/rec/train.idx',\n        preprocess_threads  = 32,\n        shuffle             = True,\n        batch_size          = 256,\n\n        data_shape          = (3, 224, 224),\n        mean_r              = mean_rgb[0],\n        mean_g              = mean_rgb[1],\n        mean_b              = mean_rgb[2],\n        std_r               = std_rgb[0],\n        std_g               = std_rgb[1],\n        std_b               = std_rgb[2],\n        rand_mirror         = True,\n        random_resized_crop = True,\n        max_aspect_ratio    = 4. / 3.,\n        min_aspect_ratio    = 3. / 4.,\n        max_random_area     = 1,\n        min_random_area     = 0.08,\n        brightness          = jitter_param,\n        saturation          = jitter_param,\n        contrast            = jitter_param,\n        pca_noise           = lighting_param,\n    )\n\n\nSince ``ImageNet`` images have much higher resolution and quality than\n``CIFAR10``, we can crop a larger image (224x224) as input to the model.\n\nFor prediction, we still need deterministic results. The function to read is:\n\n.. code-block:: python\n\n    val_data = mx.io.ImageRecordIter(\n        path_imgrec         = '~/.mxnet/datasets/imagenet/rec/val.rec',\n        path_imgidx         = '~/.mxnet/datasets/imagenet/rec/val.idx',\n        preprocess_threads  = 32,\n        shuffle             = False,\n        batch_size          = 256,\n\n        resize              = 256,\n        data_shape          = (3, 224, 224),\n        mean_r              = mean_rgb[0],\n        mean_g              = mean_rgb[1],\n        mean_b              = mean_rgb[2],\n        std_r               = std_rgb[0],\n        std_g               = std_rgb[1],\n        std_b               = std_rgb[2],\n    )\n\nIt is important to keep the normalization consistent, since trained\nmodel only works well on test data from the same distribution.\n\nThe above code works as data loader, thus we can later directly plug them into\nthe training loop.\n\nNote that we set `batch_size=256` as the total batch size on 4 GPUs.\nIt may not suit GPUs with memory smaller than 12GB. Please tune the value according to your specific configuration.\n\nPath ``'~/.mxnet/datasets/imagenet/rec'`` is the default path if you\nprepared the data `with our script <../examples_datasets/imagenet.html>`_.\n\nOptimizer, Loss and Metric\n--------------------------\n\nOptimizer is what improves the model during training. We use the popular\nNesterov accelerated gradient descent algorithm.\n\n.. code-block:: python\n\n    # Learning rate decay factor\n    lr_decay = 0.1\n    # Epochs where learning rate decays\n    lr_decay_epoch = [30, 60, 90, np.inf]\n\n    # Nesterov accelerated gradient descent\n    optimizer = 'nag'\n    # Set parameters\n    optimizer_params = {'learning_rate': 0.1, 'wd': 0.0001, 'momentum': 0.9}\n\n    # Define our trainer for net\n    trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)\n\n\nFor classification tasks, we usually use softmax cross entropy as the\nloss function.\n\n.. code-block:: python\n\n    loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\n\n\nWith 1000 classes the model may not always rate the correct answer with the highest\nrank. Besides top-1 accuracy, we also consider top-5 accuracy as a measurement\nof how well the model is doing.\n\nAt the end of every epoch, we record and print the metric scores.\n\n.. code-block:: python\n\n    acc_top1 = mx.metric.Accuracy()\n    acc_top5 = mx.metric.TopKAccuracy(5)\n    train_history = TrainingHistory(['training-top1-err', 'training-top5-err',\n                                     'validation-top1-err', 'validation-top5-err'])\n\nValidation\n----------\n\nAt the end of every training epoch, we evaluate it on the validation data set,\nand report the top-1 and top-5 error rate.\n\n.. code-block:: python\n\n    def test(ctx, val_data):\n        acc_top1_val = mx.metric.Accuracy()\n        acc_top5_val = mx.metric.TopKAccuracy(5)\n        for i, batch in enumerate(val_data):\n            data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n            label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n            outputs = [net(X) for X in data]\n            acc_top1_val.update(label, outputs)\n            acc_top5_val.update(label, outputs)\n\n        _, top1 = acc_top1_val.get()\n        _, top5 = acc_top5_val.get()\n        return (1 - top1, 1 - top5)\n\nTraining\n--------\n\nAfter all these preparation, we can finally start training!\nFollowing is the main training loop:\n\n.. code-block:: python\n\n    epochs = 120\n    lr_decay_count = 0\n    log_interval = 50\n\n    for epoch in range(epochs):\n        tic = time.time()\n        btic = time.time()\n        acc_top1.reset()\n        acc_top5.reset()\n\n        if lr_decay_period == 0 and epoch == lr_decay_epoch[lr_decay_count]:\n            trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n            lr_decay_count += 1\n\n        for i, batch in enumerate(train_data):\n            data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n            label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n            with ag.record():\n                outputs = [net(X) for X in data]\n                loss = [L(yhat, y) for yhat, y in zip(outputs, label)]\n            ag.backward(loss)\n            trainer.step(batch_size)\n            acc_top1.update(label, outputs)\n            acc_top5.update(label, outputs)\n            if log_interval and not (i + 1) % log_interval:\n                _, top1 = acc_top1.get()\n                _, top5 = acc_top5.get()\n                err_top1, err_top5 = (1-top1, 1-top5)\n                print('Epoch[%d] Batch [%d]\tSpeed: %f samples/sec\ttop1-err=%f\ttop5-err=%f'%(\n                          epoch, i, batch_size*opt.log_interval/(time.time()-btic), err_top1, err_top5))\n                btic = time.time()\n\n        _, top1 = acc_top1.get()\n        _, top5 = acc_top5.get()\n        err_top1, err_top5 = (1-top1, 1-top5)\n\n        err_top1_val, err_top5_val = test(ctx, val_data)\n        train_history.update([err_top1, err_top5, err_top1_val, err_top5_val])\n\n        print('[Epoch %d] training: err-top1=%f err-top5=%f'%(epoch, err_top1, err_top5))\n        print('[Epoch %d] time cost: %f'%(epoch, time.time()-tic))\n        print('[Epoch %d] validation: err-top1=%f err-top5=%f'%(epoch, err_top1_val, err_top5_val))\n\n\nWe can plot the top-1 error rates with:\n\n.. code-block:: python\n\n    train_history.plot(['training-top1-err', 'validation-top1-err'])\n\nIf you train the model with ``epochs=120``, the plot may look like:\n\n|image-imagenet-curve|\n\nNext Step\n---------\n\n`Model Zoo <../../model_zoo/index.html>`_ provides scripts and commands for\ntraining models on ``ImageNet``.\n\nIf you want to know what you can do with the model you just\ntrained, please read the tutorial on `Transfer learning <transfer_learning_minc.html>`__.\n\nBesides classification, deep learning models nowadays can do other exciting tasks\nlike `object detection <../examples_detection/index.html>`_ and\n`semantic segmentation <../examples_segmentation/index.html>`_.\n\n.. |image-imagenet-curve| image:: https://raw.githubusercontent.com/dmlc/web-data/master/gluoncv/classification/resnet50_v2_top1.png\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}